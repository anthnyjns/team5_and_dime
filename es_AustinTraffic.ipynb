{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AustinTrafficPy\n",
    "\n",
    "## Team5_And_Dime (MWSa)\n",
    "\n",
    "Andry Dominguez\n",
    "Tony Jones\n",
    "Brian Stoller\n",
    "Ali Apil\n",
    "Eric Staveley\n",
    "\n",
    "\n",
    "## Analysis\n",
    "\n",
    "* xxx\n",
    "\n",
    "* yyy\n",
    "\n",
    "* zzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# Import API (api_key) key from api_keys.py\n",
    "#from api_keys import api_key\n",
    "#from api_keys import gkey\n",
    "\n",
    "# Incorporated citipy to determine city based on latitude and longitude\n",
    "#from citipy import citipy\n",
    "\n",
    "# Output File (CSV)\n",
    "output_data_file = \"output_data/aus_traffic.csv\"\n",
    "\n",
    "# Range of latitudes and longitudes\n",
    "#lat_range = (-90, 90)\n",
    "#lng_range = (-180, 180)\n",
    "\n",
    "#get current time\n",
    "now = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we r using the csv though for now...    \n",
    "#BUT GOT THE QUERY TO WORK TO BRING DOWN THE 100K records!!!\n",
    "\n",
    "#real deal for looping here:\n",
    "# Build partial query URL..city to be added later\n",
    "#query_url = f\"{url}appid={api_key}&units={units}&q=\"\n",
    "\n",
    "#query_url = \"https://data.austintexas.gov/resource/r3af-2r8x.json?$limit=100000\"\n",
    "#print(query_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = requests.get(query_url).json()\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a pretty better json structure display:\n",
    "#print(json.dumps(response, indent=4, sort_keys=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(response)    # i could only find a way to get 1000...so using .csv method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(response)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Austin:  30.2672° N, 97.7431° W    per wiki...center\n",
    "#type(df[\"published_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.iloc[0,5])\n",
    "#type(df.iloc[0,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dateconv_df = pd.to_datetime(df['published_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dateconv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['published_date'] =  pd.to_datetime(df['published_date'])\n",
    "#df.head()\n",
    "#df['traffic_report_status_date_time'] =  pd.to_datetime(df['traffic_report_status_date_time'])\n",
    "#df.head()\n",
    "#len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUR ACTUAL ETL  STARTS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data record count: 98324\n"
     ]
    }
   ],
   "source": [
    "#csv method...since we could get a larger dataset\n",
    "data_file = \"Resources/Real-Time_Traffic_Incident_Reports.csv\"\n",
    "#data_file = \"//usaussfs2008.ad.global/home$/rstaveley/new_dir/Real-Time_Traffic_Incident_Reports.csv\"\n",
    "df_from_csv = pd.read_csv(data_file)\n",
    "df_from_csv.head(20)\n",
    "\n",
    "print(f\"Raw data record count: {len(df_from_csv)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-NA values per column:\n",
      "Traffic Report ID    98324\n",
      "Published Date       98324\n",
      "Issue Reported       98324\n",
      "Location             98045\n",
      "Latitude             98245\n",
      "Longitude            98245\n",
      "Address              98324\n",
      "Status               96631\n",
      "Status Date          98324\n",
      "dtype: int64\n",
      "Total of rows with complete data now: 96358\n",
      "Removing invalid longitude and latitude...\n",
      "Total number of rows with valid lat/long data: 96352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Traffic Report ID     object\n",
       "Published Date        object\n",
       "Issue Reported        object\n",
       "Location              object\n",
       "Latitude             float64\n",
       "Longitude            float64\n",
       "Address               object\n",
       "Status                object\n",
       "Status Date           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean up the data\n",
    "\n",
    "#get rid of the NaNs found in Location\n",
    "#19\t9BD7909EA32C89F68E82ED0CBE1F30A2E1D72B1C_15323...\t07/23/2018 09:39:17 PM +0000\tzSTALLED VEHICLE\tNaN\t0.000000\t0.000000\t3339 W BRAKER LN\tARCHIVED\t07/23/2018 10:15:02 PM +0000\n",
    "\n",
    "print(f\"Non-NA values per column:\\n{df_from_csv.count()}\")   #show the non-NA cells for each field\n",
    "\n",
    "#remove the rows with any empty cells\n",
    "df_from_csv_clean = df_from_csv.dropna(how='any')\n",
    "\n",
    "print(f\"Total of rows with complete data now: {len(df_from_csv_clean)}\")\n",
    "\n",
    "print(\"Removing invalid longitude and latitude...\")\n",
    "#ensure lat and long are valid.  -90<=lat<=90     -180<=lon<=180\n",
    "#lat\n",
    "row_condition = df_from_csv_clean[\"Latitude\"] <= 90\n",
    "filtered_df = df_from_csv_clean.loc[row_condition]\n",
    "row_condition = filtered_df[\"Latitude\"] >= -90\n",
    "filtered_df = filtered_df.loc[row_condition]\n",
    "\n",
    "#long\n",
    "row_condition = filtered_df[\"Longitude\"] <= 180\n",
    "filtered_df = filtered_df.loc[row_condition]\n",
    "row_condition = filtered_df[\"Longitude\"] >= -180\n",
    "filtered_df = filtered_df.loc[row_condition]\n",
    "\n",
    "print(f\"Total number of rows with valid lat/long data: {len(filtered_df)}\")\n",
    "df_from_csv_clean = filtered_df   #re-assign filtered df back to our orig name\n",
    "\n",
    "df_from_csv_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_from_csv_clean.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Traffic Report ID</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Issue Reported</th>\n",
       "      <th>Location</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Address</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C163BCD1CF90C984E9EDA4DBA311BCA369A7D1A1_15288...</td>\n",
       "      <td>2018-06-13 06:35:59</td>\n",
       "      <td>Crash Service</td>\n",
       "      <td>(30.283797,-97.741906)</td>\n",
       "      <td>30.283797</td>\n",
       "      <td>-97.741906</td>\n",
       "      <td>W 21ST ST &amp; GUADALUPE ST</td>\n",
       "      <td>ARCHIVED</td>\n",
       "      <td>2018-06-13 09:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2664C206999E7419517EE39E177797576A52201B_15381...</td>\n",
       "      <td>2018-09-29 00:52:58</td>\n",
       "      <td>Traffic Hazard</td>\n",
       "      <td>(30.380525,-97.737873)</td>\n",
       "      <td>30.380525</td>\n",
       "      <td>-97.737873</td>\n",
       "      <td>0 Mopac Sb To Research Sb Ramp</td>\n",
       "      <td>ARCHIVED</td>\n",
       "      <td>2018-09-29 01:35:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5BB246A3223A89C7FB9B2EED9A2EBDA82141406D_15438...</td>\n",
       "      <td>2018-12-03 17:49:02</td>\n",
       "      <td>Crash Service</td>\n",
       "      <td>(30.278372,-97.671971)</td>\n",
       "      <td>30.278372</td>\n",
       "      <td>-97.671971</td>\n",
       "      <td>5800 Techni Center Dr</td>\n",
       "      <td>ARCHIVED</td>\n",
       "      <td>2018-12-03 18:30:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6B20382196FB454E9FD06A33E60142902A2F0706_15288...</td>\n",
       "      <td>2018-06-13 10:15:36</td>\n",
       "      <td>Traffic Hazard</td>\n",
       "      <td>(30.339593,-97.700963)</td>\n",
       "      <td>30.339593</td>\n",
       "      <td>-97.700963</td>\n",
       "      <td>400-717 E ANDERSON LN EB</td>\n",
       "      <td>ARCHIVED</td>\n",
       "      <td>2018-06-13 11:20:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7FD2528A7609AAECB6AF825AC275F98CFDFFF8AD_15382...</td>\n",
       "      <td>2018-09-29 12:47:30</td>\n",
       "      <td>Traffic Hazard</td>\n",
       "      <td>(30.281659,-97.728551)</td>\n",
       "      <td>30.281659</td>\n",
       "      <td>-97.728551</td>\n",
       "      <td>0 N Ih 35 Ud Sb To Mlk Ramp</td>\n",
       "      <td>ARCHIVED</td>\n",
       "      <td>2018-09-29 13:00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Traffic Report ID      Published Date  \\\n",
       "0  C163BCD1CF90C984E9EDA4DBA311BCA369A7D1A1_15288... 2018-06-13 06:35:59   \n",
       "1  2664C206999E7419517EE39E177797576A52201B_15381... 2018-09-29 00:52:58   \n",
       "2  5BB246A3223A89C7FB9B2EED9A2EBDA82141406D_15438... 2018-12-03 17:49:02   \n",
       "3  6B20382196FB454E9FD06A33E60142902A2F0706_15288... 2018-06-13 10:15:36   \n",
       "4  7FD2528A7609AAECB6AF825AC275F98CFDFFF8AD_15382... 2018-09-29 12:47:30   \n",
       "\n",
       "   Issue Reported                Location   Latitude  Longitude  \\\n",
       "0   Crash Service  (30.283797,-97.741906)  30.283797 -97.741906   \n",
       "1  Traffic Hazard  (30.380525,-97.737873)  30.380525 -97.737873   \n",
       "2   Crash Service  (30.278372,-97.671971)  30.278372 -97.671971   \n",
       "3  Traffic Hazard  (30.339593,-97.700963)  30.339593 -97.700963   \n",
       "4  Traffic Hazard  (30.281659,-97.728551)  30.281659 -97.728551   \n",
       "\n",
       "                          Address    Status         Status Date  \n",
       "0        W 21ST ST & GUADALUPE ST  ARCHIVED 2018-06-13 09:00:03  \n",
       "1  0 Mopac Sb To Research Sb Ramp  ARCHIVED 2018-09-29 01:35:03  \n",
       "2           5800 Techni Center Dr  ARCHIVED 2018-12-03 18:30:03  \n",
       "3        400-717 E ANDERSON LN EB  ARCHIVED 2018-06-13 11:20:03  \n",
       "4     0 N Ih 35 Ud Sb To Mlk Ramp  ARCHIVED 2018-09-29 13:00:03  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the date strings in the DF to valid datetime types\n",
    "df_from_csv_clean['Published Date'] =  pd.to_datetime(df_from_csv_clean['Published Date'])\n",
    "#df_from_csv_clean.head()\n",
    "df_from_csv_clean['Status Date'] =  pd.to_datetime(df_from_csv_clean['Status Date'])\n",
    "df_from_csv_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest date: 2017-09-26 16:11:00\n",
      "Latest date: 2019-03-06 02:37:18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Traffic Report ID            object\n",
       "Published Date       datetime64[ns]\n",
       "Issue Reported               object\n",
       "Location                     object\n",
       "Latitude                    float64\n",
       "Longitude                   float64\n",
       "Address                      object\n",
       "Status                       object\n",
       "Status Date          datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#peek at the earliest and latest date in our DF\n",
    "earliest_date = min(df_from_csv_clean[\"Published Date\"])\n",
    "print(f\"Earliest date: {earliest_date}\")\n",
    "latest_date = max(df_from_csv_clean[\"Published Date\"])\n",
    "print(f\"Latest date: {latest_date}\")\n",
    "type(latest_date)     #confirm the type\n",
    "\n",
    "df_from_csv_clean.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows with 2018 data  68244\n"
     ]
    }
   ],
   "source": [
    "#use only 2018 data now\n",
    "#keep only 2018 data\n",
    "row_condition = df_from_csv_clean[\"Published Date\"] <= \"2018-12-31 23:59:59\"\n",
    "filtered_df = filtered_df.loc[row_condition]\n",
    "row_condition = filtered_df[\"Published Date\"] >= \"2018-01-01 00:00:01\"\n",
    "filtered_df = filtered_df.loc[row_condition]\n",
    "\n",
    "print(f\"Total number of rows with 2018 data  {len(filtered_df)}\")\n",
    "df_from_csv_clean = filtered_df   #re-assign filtered df back to our orig name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#time_mask = (df['messageDate'].dt.hour >= 13) & \\\n",
    "#            (df['messageDate'].dt.hour <= 15)\n",
    "\n",
    "#year_mask_df = (df_from_csv_clean[\"Published Date\"].dt.year > 2017) & \\\n",
    "#            (df_from_csv_clean[\"Published Date\"].dt.hour < 2019)\n",
    "\n",
    "#type(year_mask_df)\n",
    "\n",
    "#print(f\"Total number of rows with 2018 data (dt way)  {len(year_mask_df)}\")\n",
    "#df_from_csv_clean = year_mask_df   #re-assign filtered df back to our orig name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traffic Hazard                20272\n",
       "Crash Urgent                  15411\n",
       "Crash Service                 11343\n",
       "COLLISION                      4793\n",
       "Traffic Impediment             4745\n",
       "TRFC HAZD/ DEBRIS              4060\n",
       "zSTALLED VEHICLE               3008\n",
       "COLLISION WITH INJURY          1573\n",
       "LOOSE LIVESTOCK                1471\n",
       "COLLISN/ LVNG SCN              1000\n",
       "COLLISION/PRIVATE PROPERTY      250\n",
       "VEHICLE FIRE                    145\n",
       "BLOCKED DRIV/ HWY                93\n",
       "ICY ROADWAY                      21\n",
       "BOAT ACCIDENT                    20\n",
       "AUTO/ PED                        15\n",
       "TRAFFIC FATALITY                 11\n",
       "FLEET ACC/ INJURY                 9\n",
       "N / HZRD TRFC VIOL                2\n",
       "COLLISN / FTSRA                   1\n",
       "HIGH WATER                        1\n",
       "Name: Issue Reported, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at types of accidents and counts\n",
    "df_from_csv_clean[\"Issue Reported\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we care about\n",
    "#Crash Urgent, Crash Service, COLLISION, COLLISION WITH INJURY, COLLISN/ LVNG SCN, COLLISION/PRIVATE PROPERTY, AUTO/ PED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_from_csv_clean[\"Issue Reported\"].value_counts()\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4793"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"COLLISION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Employer category. Replace 'Self Employed' and 'Self' with 'Self-Employed'\n",
    "#df['Employer'] = df['Employer'].replace(\n",
    "#    {'Self Employed': 'Self-Employed', 'Self': 'Self-Employed'})\n",
    "\n",
    "#Verify clean-up.\n",
    "#df['Employer'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmaps\n",
    "\n",
    "# Google developer API key\n",
    "from api_keys import gkey\n",
    "\n",
    "# Access maps with unique API key\n",
    "gmaps.configure(api_key=gkey)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to take the lat and long and make a list for gmap\n",
    "\n",
    "aus_lat = df_from_csv_clean[\"Latitude\"]    #series\n",
    "aus_long = df_from_csv_clean[\"Longitude\"]    #series\n",
    "\n",
    "aus_lat_subset = aus_lat.head(1000)   #make a subset to test\n",
    "aus_long_subset = aus_long.head(1000)  # make a subset to test\n",
    "\n",
    "#print(type(aus_lat_subset))     #its a series\n",
    "#print(aus_lat_subset[0])        #whats the value?\n",
    "#print(type(aus_lat_subset[0]))    #its a string\n",
    "\n",
    "#print(aus_lat_subset)   #show the whole lat subset\n",
    "\n",
    "#using zip function to zip the lat and long together to a list with each element being a tuple\n",
    "aus_lat_long_list_subset = list(zip(aus_lat_subset, aus_long_subset))\n",
    "aus_lat_long_list = list(zip(aus_lat, aus_long))\n",
    "\n",
    "#print(aus_lat_long_list_subset)\n",
    "#type(aus_lat_long_list_subset[0])    #each element is a tuple...yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize the size of the figure      was   400 x 300\n",
    "figure_layout = {\n",
    "    'width': '800px',\n",
    "    'height': '600px',\n",
    "    'border': '1px solid black',\n",
    "    'padding': '1px',\n",
    "    'margin': '0 auto 0 auto'\n",
    "}\n",
    "fig = gmaps.figure(layout=figure_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a8ee7da3824d0595b82414ddf5a42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(border='1px solid black', height='600px', margin='0 auto 0 auto', padding='1px', wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign the marker layer to a variable  ..      DOING THE SUBSET HERE... TAKES ABOUT 10sec  \n",
    "\n",
    "#help(gmaps.marker_layer)\n",
    "\n",
    "markers = gmaps.marker_layer(aus_lat_long_list_subset)\n",
    "# Add the layer to the map\n",
    "fig.add_layer(markers)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(gmaps.marker_layer)\n",
    "#extracting the marker image is a bit different than plt.savefig....basically\n",
    "#gmaps only lets you save the .html  OR  you can manually dload the fig \n",
    "#within the display frame\n",
    "#per https://jupyter-gmaps.readthedocs.io/en/latest/export.html\n",
    "#\n",
    "#to export:\n",
    "#from ipywidgets.embed import embed_minimal_html\n",
    "#embed_minimal_html('exported_filename_here.html', views=[fig])\n",
    "#\n",
    "#to open the file:\n",
    "#python -m http.server 8080\n",
    "#Navigate to http://0.0.0.0:8080/exported_filename.html and you should see the export!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2908de4a409a44599b4dca9c72b2bc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = gmaps.figure(map_type='HYBRID')\n",
    "heatmap_layer = gmaps.heatmap_layer(aus_lat_long_list_subset)\n",
    "fig.add_layer(heatmap_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the marker image is a bit different than plt.savefig....basically\n",
    "#gmaps only lets you save the .html  OR  you can manually dload the fig \n",
    "#within the display frame\n",
    "#per https://jupyter-gmaps.readthedocs.io/en/latest/export.html\n",
    "#\n",
    "#to export:\n",
    "#from ipywidgets.embed import embed_minimal_html\n",
    "#embed_minimal_html('exported_filename_here.html', views=[fig])\n",
    "#\n",
    "#to open the file:\n",
    "#python -m http.server 8080\n",
    "#Navigate to http://0.0.0.0:8080/exported_filename.html and you should see the export!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
